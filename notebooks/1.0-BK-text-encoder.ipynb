{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615d0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from miscc.config import cfg\n",
    "#from GlobalAttention import GlobalAttentionGeneral as ATT_NET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d453018",
   "metadata": {},
   "source": [
    "# Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ca00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_ENCODER(nn.Module):\n",
    "    def __init__(self, ntoken, ninput=300, drop_prob=0.5,\n",
    "                 nhidden=128, nlayers=1, bidirectional=True):\n",
    "        super(RNN_ENCODER, self).__init__()\n",
    "        self.n_steps = cfg.TEXT.WORDS_NUM\n",
    "        self.ntoken = ntoken  # size of the dictionary\n",
    "        self.ninput = ninput  # size of each embedding vector\n",
    "        self.drop_prob = drop_prob  # probability of an element to be zeroed\n",
    "        self.nlayers = nlayers  # Number of recurrent layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.rnn_type = cfg.RNN_TYPE\n",
    "        if bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "        # number of features in the hidden state\n",
    "        self.nhidden = nhidden // self.num_directions\n",
    "\n",
    "        self.define_module()\n",
    "        self.init_weights()\n",
    "\n",
    "    def define_module(self):\n",
    "        self.encoder = nn.Embedding(self.ntoken, self.ninput)\n",
    "        self.drop = nn.Dropout(self.drop_prob)\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            # dropout: If non-zero, introduces a dropout layer on\n",
    "            # the outputs of each RNN layer except the last layer\n",
    "            self.rnn = nn.LSTM(self.ninput, self.nhidden,\n",
    "                               self.nlayers, batch_first=True,\n",
    "                               dropout=self.drop_prob,\n",
    "                               bidirectional=self.bidirectional)\n",
    "        elif self.rnn_type == 'GRU':\n",
    "            self.rnn = nn.GRU(self.ninput, self.nhidden,\n",
    "                              self.nlayers, batch_first=True,\n",
    "                              dropout=self.drop_prob,\n",
    "                              bidirectional=self.bidirectional)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        # Do not need to initialize RNN parameters, which have been initialized\n",
    "        # http://pytorch.org/docs/master/_modules/torch/nn/modules/rnn.html#LSTM\n",
    "        # self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        # self.decoder.bias.data.fill_(0)\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (Variable(weight.new(self.nlayers * self.num_directions,\n",
    "                                        bsz, self.nhidden).zero_()),\n",
    "                    Variable(weight.new(self.nlayers * self.num_directions,\n",
    "                                        bsz, self.nhidden).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.nlayers * self.num_directions,\n",
    "                                       bsz, self.nhidden).zero_())\n",
    "\n",
    "    def forward(self, captions, cap_lens, hidden, mask=None):\n",
    "        # input: torch.LongTensor of size batch x n_steps\n",
    "        # --> emb: batch x n_steps x ninput\n",
    "        ## drop: random zero\n",
    "        # 48 18 300\n",
    "        emb = self.drop(self.encoder(captions))\n",
    "        #\n",
    "        # Returns: a PackedSequence object\n",
    "        cap_lens = cap_lens.data.tolist()\n",
    "\n",
    "        emb = pack_padded_sequence(emb, cap_lens, batch_first=True)\n",
    "        # #hidden and memory (num_layers * num_directions, batch, hidden_size):\n",
    "        # tensor containing the initial hidden state for each element in batch.\n",
    "        # #output (batch, seq_len, hidden_size * num_directions)\n",
    "        # #or a PackedSequence object:\n",
    "        # tensor containing output features (h_t) from the last layer of RNN\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        # PackedSequence object\n",
    "        # --> (batch, seq_len, hidden_size * num_directions)\n",
    "        output = pad_packed_sequence(output, batch_first=True)[0]\n",
    "        # output = self.drop(output)\n",
    "        # --> batch x hidden_size*num_directions x seq_len\n",
    "        words_emb = output.transpose(1, 2)\n",
    "        # --> batch x num_directions*hidden_size\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            sent_emb = hidden[0].transpose(0, 1).contiguous()\n",
    "        else:\n",
    "            sent_emb = hidden.transpose(0, 1).contiguous()\n",
    "        sent_emb = sent_emb.view(-1, self.nhidden * self.num_directions)\n",
    "        return words_emb, sent_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9da176-fc68-4638-b51c-8d58a7cfd011",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b6c51d-96c9-481c-a453-858aaf70eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Block3x3_leakRelu(in_planes, out_planes):\n",
    "    block = nn.Sequential(\n",
    "        conv3x3(in_planes, out_planes),\n",
    "        nn.BatchNorm2d(out_planes),\n",
    "        nn.LeakyReLU(0.2, inplace=True)\n",
    "    )\n",
    "    return block\n",
    "\n",
    "\n",
    "# Downsale the spatial size by a factor of 2\n",
    "def downBlock(in_planes, out_planes):\n",
    "    block = nn.Sequential(\n",
    "        nn.Conv2d(in_planes, out_planes, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(out_planes),\n",
    "        nn.LeakyReLU(0.2, inplace=True)\n",
    "    )\n",
    "    return block\n",
    "\n",
    "\n",
    "# Downsale the spatial size by a factor of 16\n",
    "def encode_image_by_16times(ndf):\n",
    "    encode_img = nn.Sequential(\n",
    "        # --> state size. ndf x in_size/2 x in_size/2\n",
    "        nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # --> state size 2ndf x x in_size/4 x in_size/4\n",
    "        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # --> state size 4ndf x in_size/8 x in_size/8\n",
    "        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 4),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # --> state size 8ndf x in_size/16 x in_size/16\n",
    "        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 8),\n",
    "        nn.LeakyReLU(0.2, inplace=True)\n",
    "    )\n",
    "    return encode_img\n",
    "\n",
    "\n",
    "class D_GET_LOGITS(nn.Module):\n",
    "    def __init__(self, ndf, nef, bcondition=False):\n",
    "        super(D_GET_LOGITS, self).__init__()\n",
    "        self.df_dim = ndf\n",
    "        self.ef_dim = nef\n",
    "        self.bcondition = bcondition\n",
    "        if self.bcondition:\n",
    "            self.jointConv = Block3x3_leakRelu(ndf * 8 + nef, ndf * 8)\n",
    "\n",
    "        self.outlogits = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, h_code, c_code=None):\n",
    "        if self.bcondition and c_code is not None:\n",
    "            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n",
    "            c_code = c_code.repeat(1, 1, 4, 4)\n",
    "            h_c_code = torch.cat((h_code, c_code), 1)\n",
    "            h_c_code = self.jointConv(h_c_code)\n",
    "        else:\n",
    "            h_c_code = h_code\n",
    "\n",
    "        output = self.outlogits(h_c_code)\n",
    "        return output.view(-1)\n",
    "\n",
    "\n",
    "# For 64 x 64 images\n",
    "class D_NET64(nn.Module):\n",
    "    def __init__(self, b_jcu=True):\n",
    "        super(D_NET64, self).__init__()\n",
    "        ndf = cfg.GAN.DF_DIM\n",
    "        nef = cfg.TEXT.EMBEDDING_DIM\n",
    "        self.img_code_s16 = encode_image_by_16times(ndf)\n",
    "        if b_jcu:\n",
    "            self.UNCOND_DNET = D_GET_LOGITS(ndf, nef, bcondition=False)\n",
    "        else:\n",
    "            self.UNCOND_DNET = None\n",
    "        self.COND_DNET = D_GET_LOGITS(ndf, nef, bcondition=True)\n",
    "\n",
    "    def forward(self, x_var):\n",
    "        x_code4 = self.img_code_s16(x_var)  # 4 x 4 x 8df\n",
    "        return x_code4\n",
    "\n",
    "\n",
    "# For 128 x 128 images\n",
    "class D_NET128(nn.Module):\n",
    "    def __init__(self, b_jcu=True):\n",
    "        super(D_NET128, self).__init__()\n",
    "        ndf = cfg.GAN.DF_DIM\n",
    "        nef = cfg.TEXT.EMBEDDING_DIM\n",
    "        self.img_code_s16 = encode_image_by_16times(ndf)\n",
    "        self.img_code_s32 = downBlock(ndf * 8, ndf * 16)\n",
    "        self.img_code_s32_1 = Block3x3_leakRelu(ndf * 16, ndf * 8)\n",
    "        #\n",
    "        if b_jcu:\n",
    "            self.UNCOND_DNET = D_GET_LOGITS(ndf, nef, bcondition=False)\n",
    "        else:\n",
    "            self.UNCOND_DNET = None\n",
    "        self.COND_DNET = D_GET_LOGITS(ndf, nef, bcondition=True)\n",
    "\n",
    "    def forward(self, x_var):\n",
    "        x_code8 = self.img_code_s16(x_var)   # 8 x 8 x 8df\n",
    "        x_code4 = self.img_code_s32(x_code8)   # 4 x 4 x 16df\n",
    "        x_code4 = self.img_code_s32_1(x_code4)  # 4 x 4 x 8df\n",
    "        return x_code4\n",
    "\n",
    "\n",
    "# For 256 x 256 images\n",
    "class D_NET256(nn.Module):\n",
    "    def __init__(self, b_jcu=True):\n",
    "        super(D_NET256, self).__init__()\n",
    "        ndf = cfg.GAN.DF_DIM\n",
    "        nef = cfg.TEXT.EMBEDDING_DIM\n",
    "        self.img_code_s16 = encode_image_by_16times(ndf)\n",
    "        self.img_code_s32 = downBlock(ndf * 8, ndf * 16)\n",
    "        self.img_code_s64 = downBlock(ndf * 16, ndf * 32)\n",
    "        self.img_code_s64_1 = Block3x3_leakRelu(ndf * 32, ndf * 16)\n",
    "        self.img_code_s64_2 = Block3x3_leakRelu(ndf * 16, ndf * 8)\n",
    "        if b_jcu:\n",
    "            self.UNCOND_DNET = D_GET_LOGITS(ndf, nef, bcondition=False)\n",
    "        else:\n",
    "            self.UNCOND_DNET = None\n",
    "        self.COND_DNET = D_GET_LOGITS(ndf, nef, bcondition=True)\n",
    "\n",
    "    def forward(self, x_var):\n",
    "        x_code16 = self.img_code_s16(x_var)\n",
    "        x_code8 = self.img_code_s32(x_code16)\n",
    "        x_code4 = self.img_code_s64(x_code8)\n",
    "        x_code4 = self.img_code_s64_1(x_code4)\n",
    "        x_code4 = self.img_code_s64_2(x_code4)\n",
    "        return x_code4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3920d1-cadb-49b4-aa98-240bc151ab64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taim",
   "language": "python",
   "name": "taim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
