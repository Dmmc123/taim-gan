{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LSTM-based textual encoder for tokenized input\"\"\"\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    \"\"\"Simple text encoder based on RNN\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size: int, emb_dim: int, hidden_dim: int) -> None:\n",
    "        \"\"\"\n",
    "        Initialize embeddings lookup for tokens and main LSTM\n",
    "\n",
    "        :param vocab_size:\n",
    "            Size of created vocabulary for textual input. L from paper\n",
    "        :param emb_dim: Length of embeddings for each word.\n",
    "        :param hidden_dim:\n",
    "            Length of hidden state of a LSTM cell. 2 x hidden_dim = C (from LWGAN paper)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embs = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor) -> Any:\n",
    "        \"\"\"\n",
    "        Propagate the text token input through the LSTM and return\n",
    "        two types of embeddings: word-level and sentence-level\n",
    "\n",
    "        :param torch.Tensor tokens: Input text tokens from vocab\n",
    "        :return: Word-level embeddings (BxCxL) and sentence-level embeddings (BxC)\n",
    "        :rtype: Any\n",
    "        \"\"\"\n",
    "        embs = self.embs(tokens)\n",
    "        output, (hidden_states, _) = self.lstm(embs)\n",
    "        word_embs = torch.transpose(output, 1, 2)\n",
    "        sent_embs = torch.cat((hidden_states[-1, :, :], hidden_states[0, :, :]), dim=1)\n",
    "        return word_embs, sent_embs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 18])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "emb_dim = 300\n",
    "\n",
    "batch_size = 32\n",
    "max_seq_len = 18\n",
    "D = 256\n",
    "gamma1 = 4 # for both bird, coco\n",
    "gamma2 = 5 # for both bird, coco\n",
    "gamma3 = 10 # for both bird, coco\n",
    "queryL = 10\n",
    "\n",
    "hidden_dim = D // 2\n",
    "\n",
    "text_encoder = TextEncoder(vocab_size, emb_dim, hidden_dim)\n",
    "input_tokens = torch.randint(0, vocab_size, (batch_size, max_seq_len))\n",
    "input_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 139, 1053, 2849, 4876, 2027,  865, 3506,  620,  323, 3078, 3034, 4910,\n",
       "        3889,  999, 2298, 3799, 2169, 2054])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 256, 18]), torch.Size([32, 256]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embs, sent_embs = text_encoder(input_tokens)\n",
    "word_embs.shape, sent_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = word_embs[0, :, :10].unsqueeze(0).contiguous()\n",
    "word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 256, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = word.repeat(batch_size, 1, 1)\n",
    "word.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## func_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_attention(word):\n",
    "    batch_size, queryL = word.size(0), word.size(2) #queryL is the length of the sequence\n",
    "    img_features = torch.randn(batch_size, D, 17, 17)\n",
    "    context = img_features\n",
    "    ih, iw = context.size(2), context.size(3)\n",
    "\n",
    "    sourceL = ih * iw\n",
    "\n",
    "    context = context.view(batch_size, -1, sourceL) #batch x D x N\n",
    "    contextT = torch.transpose(context, 1, 2).contiguous() #batch x N x D\n",
    "\n",
    "    attn = contextT @ word\n",
    "    attn = attn.view(batch_size * sourceL, queryL) #batch*N x queryL\n",
    "    attn = nn.Softmax(dim = 1)(attn)\n",
    "    attn = attn.view(batch_size, sourceL, queryL) #batch x N x queryL\n",
    "    attn = torch.transpose(attn, 1, 2).contiguous() #batch x queryL x N\n",
    "    attn = attn.view(batch_size * queryL, sourceL) #batch*queryL x N\n",
    "    attn = attn * gamma1\n",
    "    attn = nn.Softmax(dim = 1)(attn)\n",
    "    attn = attn.view(batch_size, queryL, sourceL) #batch x queryL x N\n",
    "    attnT = torch.transpose(attn, 1, 2).contiguous() #batch x N x queryL\n",
    "\n",
    "    weighted_context = context @ attnT #batch x D x queryL\n",
    "    return weighted_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(x1, x2, dim=1, eps=1e-8):\n",
    "    w12 = torch.sum(x1 * x2, dim)\n",
    "    w1 = torch.norm(x1, 2, dim)\n",
    "    w2 = torch.norm(x2, 2, dim)\n",
    "    return (w12 / (w1 * w2).clamp(min=eps)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = word.transpose(1, 2).contiguous() #batch x queryL x D\n",
    "weighted_context = weighted_context.transpose(1, 2).contiguous() #batch x queryL x D\n",
    "\n",
    "word = word.view(batch_size * queryL, -1) #batch*queryL x D\n",
    "weighted_context = weighted_context.view(batch_size * queryL, -1) #batch*queryL x D\n",
    "\n",
    "row_sim = cosine_sim(word, weighted_context)\n",
    "row_sim = row_sim.view(batch_size, queryL) #batch x queryL\n",
    "\n",
    "row_sim = torch.exp(row_sim * gamma2) #batch x queryL\n",
    "row_sim = row_sim.sum(dim = 1, keepdim = True) #batch x 1\n",
    "\n",
    "row_sim = torch.log(row_sim) #batch x 1\n",
    "sim_list.append(row_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with batch loop and combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "emb_dim = 300\n",
    "\n",
    "batch_size = 4\n",
    "max_seq_len = 18\n",
    "D = 256\n",
    "gamma1 = 4 # for both bird, coco\n",
    "gamma2 = 5 # for both bird, coco\n",
    "gamma3 = 10 # for both bird, coco\n",
    "\n",
    "hidden_dim = D // 2\n",
    "\n",
    "text_encoder = TextEncoder(vocab_size, emb_dim, hidden_dim)\n",
    "input_tokens = torch.randint(0, vocab_size, (batch_size, max_seq_len))\n",
    "\n",
    "word_embs, sent_embs = text_encoder(input_tokens)\n",
    "\n",
    "sim_list = []\n",
    "\n",
    "for batch_idx in range(batch_size):\n",
    "    word = word_embs[batch_idx, :, :10].unsqueeze(0).contiguous()\n",
    "    word = word.repeat(batch_size, 1, 1)\n",
    "\n",
    "    weighted_context = func_attention(word)\n",
    "\n",
    "    word = word.transpose(1, 2).contiguous() #batch x queryL x D\n",
    "    weighted_context = weighted_context.transpose(1, 2).contiguous() #batch x queryL x D\n",
    "\n",
    "    word = word.view(batch_size * queryL, -1) #batch*queryL x D\n",
    "    weighted_context = weighted_context.view(batch_size * queryL, -1) #batch*queryL x D\n",
    "\n",
    "    row_sim = cosine_sim(word, weighted_context)\n",
    "    row_sim = row_sim.view(batch_size, queryL) #batch x queryL\n",
    "\n",
    "    row_sim = torch.exp(row_sim * gamma2) #batch x queryL\n",
    "    row_sim = row_sim.sum(dim = 1, keepdim = True) #batch x 1\n",
    "\n",
    "    row_sim = torch.log(row_sim) #batch x 1\n",
    "    sim_list.append(row_sim)\n",
    "\n",
    "similarities = torch.cat(sim_list, dim = 1) #batch x batch\n",
    "similarities.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10],\n",
      "        [10],\n",
      "        [ 8],\n",
      "        [ 1]])\n"
     ]
    }
   ],
   "source": [
    "print(class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "class_ids = torch.randint(1, 11, (batch_size, 1))\n",
    "\n",
    "masks = []\n",
    "\n",
    "for i in range(batch_size):\n",
    "    mask = (class_ids == class_ids[i]).numpy().astype(np.uint8)\n",
    "    mask[i] = 0\n",
    "    masks.append(mask.reshape(1, -1))\n",
    "\n",
    "masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 1, 0, 0]], dtype=uint8),\n",
       " array([[1, 0, 0, 0]], dtype=uint8),\n",
       " array([[0, 0, 0, 0]], dtype=uint8),\n",
       " array([[0, 0, 0, 0]], dtype=uint8)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = np.concatenate(masks, axis = 0)\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False, False],\n",
       "        [ True, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = torch.BoolTensor(masks)\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.2583,   -inf, 4.2598, 4.4091],\n",
       "        [  -inf, 4.3158, 4.1988, 4.1712],\n",
       "        [4.2803, 4.2669, 4.1280, 4.3717],\n",
       "        [4.4219, 4.3610, 4.1831, 4.2365]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.data.masked_fill_(masks, -float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2860, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.LongTensor(range(batch_size))\n",
    "loss0 = nn.CrossEntropyLoss()(similarities, labels)\n",
    "loss0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ids == class_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,    -inf,  0.2741, -0.6443],\n",
       "        [ 0.0257,  0.0000,  2.5821, -1.0813],\n",
       "        [-1.8071,  0.1304,  0.0000,  0.9694],\n",
       "        [-0.2055,    -inf,    -inf,  0.0000]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn((batch_size, batch_size))\n",
    "classes = torch.randint(1, 11, (batch_size, 1))\n",
    "masks = torch.randn((batch_size, batch_size)) > 0.5\n",
    "a.data.masked_fill_(masks, -float('inf'))\n",
    "for i in range(batch_size):\n",
    "    a[i, i] = 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4959)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label = torch.tensor(range(batch_size), dtype=torch.long)\n",
    "#init cross-entropy loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss0 = criterion(a, true_label)\n",
    "loss0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0973)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.tensor([[2, 3, 5], [4, 0, -1]], dtype = torch.float32) #batch x dim\n",
    "labels = [2, 0] #batch\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()(preds, torch.tensor(labels))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., -inf])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([0, 2, -float(\"inf\")])\n",
    "sm = nn.Softmax(dim = 0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1192, 0.8808, 0.0000]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_out = sm(a)\n",
    "sm_out = sm_out.unsqueeze(0)\n",
    "sm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(inf)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll = nn.NLLLoss()\n",
    "nll(torch.log(sm_out), torch.tensor([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['002.Laysan_Albatross/Laysan_Albatross_0002_1027',\n",
       " '002.Laysan_Albatross/Laysan_Albatross_0003_1033',\n",
       " '002.Laysan_Albatross/Laysan_Albatross_0082_524',\n",
       " '002.Laysan_Albatross/Laysan_Albatross_0044_784',\n",
       " '002.Laysan_Albatross/Laysan_Albatross_0070_788']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../../Repo/src/data/birds/train/filenames.pickle\"\n",
    "\n",
    "with open(file_path, \"rb\") as f:\n",
    "    filenames = pickle.load(f)\n",
    "\n",
    "filenames[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../../Repo/src/data/birds/train/class_info.pickle\"\n",
    "import pickle\n",
    "with open(path, 'rb') as f:\n",
    "    class_info = pickle.load(f, encoding='latin1')\n",
    "\n",
    "class_info[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8855"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find unique classes\n",
    "classes = set()\n",
    "for i in range(len(class_info)):\n",
    "    classes.add(class_info[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "batch_size = 4\n",
    "class_ids = torch.randint(1, 11, (batch_size, 1))\n",
    "mask = (class_ids == class_ids[0])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert bool tensor mask to torch.int\n",
    "mask = mask.type(torch.int)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2904,  2.0137,  0.9687],\n",
       "         [-1.4123,  0.5085, -0.4709]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "D = 2\n",
    "numb_words = 3\n",
    "actual_words = torch.randn(1, D, numb_words)\n",
    "actual_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2904,  2.0137,  0.9687],\n",
       "         [-1.4123,  0.5085, -0.4709]],\n",
       "\n",
       "        [[-1.2904,  2.0137,  0.9687],\n",
       "         [-1.4123,  0.5085, -0.4709]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_words_ex = actual_words.expand(batch_size, -1, -1) # shape: (batch, D, numb_words)\n",
    "actual_words_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_words_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes the mean squared error between two tensors.\n",
    "\n",
    "    Args:\n",
    "        input: The input tensor.\n",
    "        target: The target tensor.\n",
    "    \"\"\"\n",
    "    return nn.MSELoss()(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9986)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = torch.randn(4, 128, 128, 128)\n",
    "fake = torch.randn(4, 128, 128, 128)\n",
    "\n",
    "mean_squared_error(real, fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9986)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.mse_loss(real, fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.9519],\n",
       "         [3.3639],\n",
       "         [2.8623],\n",
       "         [2.7975]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "batch = 4\n",
    "D = 10\n",
    "global_incept_feat = torch.randn(1, batch, D)\n",
    "incept_feat_norm = torch.norm(global_incept_feat, 2, dim=2, keepdim=True)\n",
    "incept_feat_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incept_feat_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.9519],\n",
       "         [3.3639],\n",
       "         [2.8623],\n",
       "         [2.7975]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_norm = torch.linalg.norm(global_incept_feat, ord = 2, dim = 2, keepdim = True)\n",
    "new_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function norm in module torch.functional:\n",
      "\n",
      "norm(input, p='fro', dim=None, keepdim=False, out=None, dtype=None)\n",
      "    Returns the matrix norm or vector norm of a given tensor.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "        torch.norm is deprecated and may be removed in a future PyTorch release.\n",
      "        Its documentation and behavior may be incorrect, and it is no longer\n",
      "        actively maintained.\n",
      "    \n",
      "        Use :func:`torch.linalg.norm`, instead, or :func:`torch.linalg.vector_norm`\n",
      "        when computing vector norms and :func:`torch.linalg.matrix_norm` when\n",
      "        computing matrix norms. Note, however, the signature for these functions\n",
      "        is slightly different than the signature for torch.norm.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): The input tensor. Its data type must be either a floating\n",
      "            point or complex type. For complex inputs, the norm is calculated using the\n",
      "            absolute value of each element. If the input is complex and neither\n",
      "            :attr:`dtype` nor :attr:`out` is specified, the result's data type will\n",
      "            be the corresponding floating point type (e.g. float if :attr:`input` is\n",
      "            complexfloat).\n",
      "    \n",
      "        p (int, float, inf, -inf, 'fro', 'nuc', optional): the order of norm. Default: ``'fro'``\n",
      "            The following norms can be calculated:\n",
      "    \n",
      "            ======  ==============  ==========================\n",
      "            ord     matrix norm     vector norm\n",
      "            ======  ==============  ==========================\n",
      "            'fro'   Frobenius norm  --\n",
      "            'nuc'   nuclear norm    --\n",
      "            Number  --              sum(abs(x)**ord)**(1./ord)\n",
      "            ======  ==============  ==========================\n",
      "    \n",
      "            The vector norm can be calculated across any number of dimensions.\n",
      "            The corresponding dimensions of :attr:`input` are flattened into\n",
      "            one dimension, and the norm is calculated on the flattened\n",
      "            dimension.\n",
      "    \n",
      "            Frobenius norm produces the same result as ``p=2`` in all cases\n",
      "            except when :attr:`dim` is a list of three or more dims, in which\n",
      "            case Frobenius norm throws an error.\n",
      "    \n",
      "            Nuclear norm can only be calculated across exactly two dimensions.\n",
      "    \n",
      "        dim (int, tuple of ints, list of ints, optional):\n",
      "            Specifies which dimension or dimensions of :attr:`input` to\n",
      "            calculate the norm across. If :attr:`dim` is ``None``, the norm will\n",
      "            be calculated across all dimensions of :attr:`input`. If the norm\n",
      "            type indicated by :attr:`p` does not support the specified number of\n",
      "            dimensions, an error will occur.\n",
      "        keepdim (bool, optional): whether the output tensors have :attr:`dim`\n",
      "            retained or not. Ignored if :attr:`dim` = ``None`` and\n",
      "            :attr:`out` = ``None``. Default: ``False``\n",
      "        out (Tensor, optional): the output tensor. Ignored if\n",
      "            :attr:`dim` = ``None`` and :attr:`out` = ``None``.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of\n",
      "            returned tensor. If specified, the input tensor is casted to\n",
      "            :attr:`dtype` while performing the operation. Default: None.\n",
      "    \n",
      "    .. note::\n",
      "        Even though ``p='fro'`` supports any number of dimensions, the true\n",
      "        mathematical definition of Frobenius norm only applies to tensors with\n",
      "        exactly two dimensions. :func:`torch.linalg.norm` with ``ord='fro'`` aligns\n",
      "        with the mathematical definition, since it can only be applied across\n",
      "        exactly two dimensions.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> import torch\n",
      "        >>> a = torch.arange(9, dtype= torch.float) - 4\n",
      "        >>> b = a.reshape((3, 3))\n",
      "        >>> torch.norm(a)\n",
      "        tensor(7.7460)\n",
      "        >>> torch.norm(b)\n",
      "        tensor(7.7460)\n",
      "        >>> torch.norm(a, float('inf'))\n",
      "        tensor(4.)\n",
      "        >>> torch.norm(b, float('inf'))\n",
      "        tensor(4.)\n",
      "        >>> c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float)\n",
      "        >>> torch.norm(c, dim=0)\n",
      "        tensor([1.4142, 2.2361, 5.0000])\n",
      "        >>> torch.norm(c, dim=1)\n",
      "        tensor([3.7417, 4.2426])\n",
      "        >>> torch.norm(c, p=1, dim=1)\n",
      "        tensor([6., 6.])\n",
      "        >>> d = torch.arange(8, dtype= torch.float).reshape(2,2,2)\n",
      "        >>> torch.norm(d, dim=(1,2))\n",
      "        tensor([ 3.7417, 11.2250])\n",
      "        >>> torch.norm(d[0, :, :]), torch.norm(d[1, :, :])\n",
      "        (tensor(3.7417), tensor(11.2250))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 5\n",
    "cap_len = torch.randint(0, 4, (5, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_words = cap_len[0]\n",
    "numb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.arange(16).reshape(4, 4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8,  9, 10],\n",
       "        [12, 13, 14]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2:, :numb_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = 8\n",
    "D = 10\n",
    "\n",
    "global_incept_feat = torch.randn(batch, D)\n",
    "sent_emb = torch.randn(batch, D)\n",
    "\n",
    "incept_feat_norm = torch.linalg.norm(global_incept_feat, ord=2, dim=1, keepdim=True)\n",
    "# shape: (1, batch, 1)\n",
    "sent_emb_norm = torch.linalg.norm(sent_emb, ord=2, dim=1, keepdim=True)\n",
    "\n",
    "# shape: (1, batch, batch)\n",
    "global_match_score = global_incept_feat @ (sent_emb.transpose(0, 1))\n",
    "# shape: (1, batch, batch)\n",
    "global_match_norm = incept_feat_norm @ (sent_emb_norm.transpose(0, 1))\n",
    "\n",
    "global_match_score = (global_match_score / global_match_norm).clamp(min=1e-8)\n",
    "global_match_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(global_incept_feat, sent_emb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n",
      "tensor([[3.8115e-01, 4.5633e-01, 1.0000e-08, 7.6416e-01, 8.5716e-02, 4.4833e-01,\n",
      "         1.0000e-08, 1.0000e-08],\n",
      "        [1.0000e-08, 4.0698e-02, 9.7689e-02, 2.7422e-01, 1.0000e-08, 1.0000e-08,\n",
      "         2.1443e-01, 6.9974e-02],\n",
      "        [1.0000e-08, 4.4397e-01, 5.5527e-03, 1.7717e-01, 1.0000e-08, 1.8297e-01,\n",
      "         4.8066e-01, 2.8027e-02],\n",
      "        [1.5388e-01, 2.2808e-01, 1.0000e-08, 4.5550e-01, 1.3103e-01, 3.7871e-01,\n",
      "         1.0000e-08, 2.0979e-01],\n",
      "        [1.8245e-01, 2.4587e-01, 1.0000e-08, 1.0000e-08, 5.8311e-01, 4.6521e-01,\n",
      "         1.0000e-08, 1.0000e-08],\n",
      "        [4.6113e-01, 6.0762e-02, 1.7996e-01, 3.4705e-01, 3.5238e-01, 1.0000e-08,\n",
      "         1.0000e-08, 1.0000e-08],\n",
      "        [1.3616e-01, 1.0000e-08, 4.2197e-01, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "         1.0000e-08, 1.0000e-08],\n",
      "        [2.1762e-01, 1.0000e-08, 1.0000e-08, 1.0000e-08, 2.4924e-01, 2.7656e-01,\n",
      "         1.0000e-08, 1.0000e-08]])\n"
     ]
    }
   ],
   "source": [
    "batch = 8\n",
    "D = 10\n",
    "\n",
    "global_incept_feat = torch.randn(1, batch, D)\n",
    "sent_emb = torch.randn(1, batch, D)\n",
    "\n",
    "incept_feat_norm = torch.linalg.norm(global_incept_feat, ord=2, dim=2, keepdim=True)\n",
    "# shape: (1, batch, 1)\n",
    "sent_emb_norm = torch.linalg.norm(sent_emb, ord=2, dim=2, keepdim=True)\n",
    "\n",
    "# shape: (1, batch, batch)\n",
    "global_match_score = global_incept_feat @ (sent_emb.transpose(1, 2))\n",
    "# shape: (1, batch, batch)\n",
    "global_match_norm = incept_feat_norm @ (sent_emb_norm.transpose(1, 2))\n",
    "\n",
    "global_match_score = (global_match_score / global_match_norm).clamp(min=1e-8)\n",
    "score_1 = global_match_score.squeeze()\n",
    "print(score_1.shape)\n",
    "print(score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8115e-01, 1.0000e-08, 1.0000e-08, 1.5388e-01, 1.8245e-01, 4.6113e-01,\n",
       "         1.3616e-01, 2.1762e-01],\n",
       "        [4.5633e-01, 4.0698e-02, 4.4397e-01, 2.2808e-01, 2.4587e-01, 6.0762e-02,\n",
       "         1.0000e-08, 1.0000e-08],\n",
       "        [1.0000e-08, 9.7689e-02, 5.5527e-03, 1.0000e-08, 1.0000e-08, 1.7996e-01,\n",
       "         4.2197e-01, 1.0000e-08],\n",
       "        [7.6416e-01, 2.7422e-01, 1.7717e-01, 4.5550e-01, 1.0000e-08, 3.4705e-01,\n",
       "         1.0000e-08, 1.0000e-08],\n",
       "        [8.5716e-02, 1.0000e-08, 1.0000e-08, 1.3103e-01, 5.8311e-01, 3.5238e-01,\n",
       "         1.0000e-08, 2.4924e-01],\n",
       "        [4.4833e-01, 1.0000e-08, 1.8297e-01, 3.7871e-01, 4.6521e-01, 1.0000e-08,\n",
       "         1.0000e-08, 2.7656e-01],\n",
       "        [1.0000e-08, 2.1443e-01, 4.8066e-01, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
       "         1.0000e-08, 1.0000e-08],\n",
       "        [1.0000e-08, 6.9974e-02, 2.8027e-02, 2.0979e-01, 1.0000e-08, 1.0000e-08,\n",
       "         1.0000e-08, 1.0000e-08]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n",
      "tensor([[3.8115e-01, 4.5633e-01, 1.0000e-08, 7.6416e-01, 8.5716e-02, 4.4833e-01,\n",
      "         1.0000e-08, 1.0000e-08],\n",
      "        [1.0000e-08, 4.0698e-02, 9.7689e-02, 2.7422e-01, 1.0000e-08, 1.0000e-08,\n",
      "         2.1443e-01, 6.9974e-02],\n",
      "        [1.0000e-08, 4.4397e-01, 5.5527e-03, 1.7717e-01, 1.0000e-08, 1.8297e-01,\n",
      "         4.8066e-01, 2.8027e-02],\n",
      "        [1.5388e-01, 2.2808e-01, 1.0000e-08, 4.5550e-01, 1.3103e-01, 3.7871e-01,\n",
      "         1.0000e-08, 2.0979e-01],\n",
      "        [1.8245e-01, 2.4587e-01, 1.0000e-08, 1.0000e-08, 5.8311e-01, 4.6521e-01,\n",
      "         1.0000e-08, 1.0000e-08],\n",
      "        [4.6113e-01, 6.0762e-02, 1.7996e-01, 3.4705e-01, 3.5238e-01, 1.0000e-08,\n",
      "         1.0000e-08, 1.0000e-08],\n",
      "        [1.3616e-01, 1.0000e-08, 4.2197e-01, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "         1.0000e-08, 1.0000e-08],\n",
      "        [2.1762e-01, 1.0000e-08, 1.0000e-08, 1.0000e-08, 2.4924e-01, 2.7656e-01,\n",
      "         1.0000e-08, 1.0000e-08]])\n"
     ]
    }
   ],
   "source": [
    "global_incept_feat = global_incept_feat.squeeze() # shape: (batch, D)\n",
    "sent_emb = sent_emb.squeeze() # shape: (batch, D)\n",
    "\n",
    "incept_feat_norm = torch.linalg.norm(global_incept_feat, dim=1)\n",
    "sent_emb_norm = torch.linalg.norm(sent_emb, dim=1)\n",
    "\n",
    "\n",
    "global_match_score = global_incept_feat @ (sent_emb.transpose(0, 1)) # shape: (batch, batch)\n",
    "\n",
    "global_match_norm = torch.outer(incept_feat_norm, sent_emb_norm)\n",
    "\n",
    "global_match_score = (global_match_score / global_match_norm).clamp(min=1e-8)\n",
    "score_2 = global_match_score\n",
    "print(score_2.shape)\n",
    "print(score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(score_1 == score_2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_match_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1320, -0.3395, -0.5890, -0.3123,  0.2288, -0.5150,  0.0653, -0.1336]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(global_incept_feat, sent_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incept_feat_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1320, -0.3395, -0.5890, -0.3123,  0.2288, -0.5150,  0.0653, -0.1336]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(global_incept_feat, sent_emb, dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.5492],\n",
       "         [3.3422],\n",
       "         [2.9029],\n",
       "         [4.8241],\n",
       "         [4.1402],\n",
       "         [3.1059],\n",
       "         [2.8581],\n",
       "         [3.0571]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(global_incept_feat, ord=2, dim=2, keepdim = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod = global_incept_feat @ (sent_emb.transpose(1, 2))\n",
    "prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3945,  1.3150, -2.5683,  2.5527, -2.0376, -0.6110,  1.1983,\n",
       "          -3.0688],\n",
       "         [ 1.3612, -1.9301,  1.9556, -3.4314,  3.9495,  2.2956,  0.2838,\n",
       "           1.0145],\n",
       "         [ 2.5207,  0.9166, -3.6000, -1.4178, -6.2234, -4.9215, -2.0611,\n",
       "          -4.3011],\n",
       "         [ 4.9064, -0.1778,  3.8847, -4.2231,  0.3811, -1.4143,  3.3765,\n",
       "          -3.1960],\n",
       "         [-5.2942,  0.9090,  0.2634,  4.6281,  3.6519,  0.7313,  3.9706,\n",
       "          -0.9218],\n",
       "         [ 2.4633, -0.1238, -2.6223, -2.1713,  0.2895, -5.0272,  0.2796,\n",
       "          -6.2209],\n",
       "         [ 1.4725,  0.6404,  1.4863, -1.5605,  1.9158, -2.4277,  0.4420,\n",
       "          -1.2881],\n",
       "         [-3.1161,  1.0281, -4.2088,  2.0383, -4.8242, -1.3027, -0.4504,\n",
       "          -1.3872]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = torch.tensor([[1, 2, 3], [4, 5, 6]]).float()\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.7417, 8.7750])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(V, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sqrt(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.774964387392123"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('taim_gan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff391ce501632d9821a13368a005649f389d67d59244fa9607f94396d974a71b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
