{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "p = torch.tensor([3, 4, 5.])\n",
    "avg_p = torch.tensor([1, 2., 3])\n",
    "#avg_p.mul_(0.999).add_(0.001, p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_p = avg_p * 0.999\n",
    "avg_p = avg_p + 0.001 * p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_p = 0.999 * avg_p + 0.001 * p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0020, 2.0020, 3.0020])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "batch_size = 4\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.FloatTensor(batch_size).fill_(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Simple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(\n",
    "    discriminator: Any,\n",
    "    inception_encoder: Any,\n",
    "    fake_imgs: torch.Tensor,\n",
    "    real_labels: torch.Tensor,\n",
    "    words_emb: torch.Tensor,\n",
    "    sent_emb: torch.Tensor,\n",
    "    match_labels: torch.Tensor,\n",
    "    cap_lens: torch.Tensor,\n",
    "    class_ids: torch.Tensor,\n",
    "    vgg_encoder: Any,\n",
    "    real_imgs: torch.Tensor,\n",
    "    device: Any,\n",
    "    const_dict: dict[Any, Any],\n",
    ") -> Any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "mu = torch.tensor([1, 2, 3])\n",
    "\n",
    "# KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "# KLD = torch.mean(KLD_element).mul_(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.randn(2, 10)\n",
    "logvar = torch.randn(2, 10)\n",
    "KLD_element = 1 + logvar - (mu ** 2 + torch.exp(logvar))\n",
    "KLD = -0.5 * torch.mean(KLD_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.2742)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(KLD_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Conditioning Augmentation Module\"\"\"\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CondAugmentation(nn.Module):\n",
    "    \"\"\"Conditioning Augmentation Module\"\"\"\n",
    "\n",
    "    def __init__(self, D: int, conditioning_dim: int):\n",
    "        \"\"\"\n",
    "        :param D: Dimension of the text embedding space [D from AttnGAN paper]\n",
    "        :param conditioning_dim: Dimension of the conditioning space\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.cond_dim = conditioning_dim\n",
    "        self.cond_augment = nn.Linear(D, conditioning_dim * 4, bias=True)\n",
    "        self.glu = nn.GLU(dim=1)\n",
    "\n",
    "    def encode(self, text_embedding: torch.Tensor) -> Any:\n",
    "        \"\"\"\n",
    "        This function encodes the text embedding into the conditioning space\n",
    "        :param text_embedding: Text embedding\n",
    "        :return: Conditioning embedding\n",
    "        \"\"\"\n",
    "        x_tensor = self.glu(self.cond_augment(text_embedding))\n",
    "        mu_tensor = x_tensor[:, : self.cond_dim]\n",
    "        logvar = x_tensor[:, self.cond_dim :]\n",
    "        return mu_tensor, logvar\n",
    "\n",
    "    def sample(self, mu_tensor: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        This function samples from the Gaussian distribution\n",
    "        :param mu: Mean of the Gaussian distribution\n",
    "        :param logvar: Log variance of the Gaussian distribution\n",
    "        :return: Sample from the Gaussian distribution\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(\n",
    "            std\n",
    "        )  # check if this should add requires_grad = True to this tensor?\n",
    "        return mu_tensor + eps * std\n",
    "\n",
    "    def forward(self, text_embedding: torch.Tensor) -> Any:\n",
    "        \"\"\"\n",
    "        This function encodes the text embedding into the conditioning space,\n",
    "        and samples from the Gaussian distribution.\n",
    "        :param text_embedding: Text embedding\n",
    "        :return c_hat: Conditioning embedding (C^ from StackGAN++ paper)\n",
    "        :return mu: Mean of the Gaussian distribution\n",
    "        :return logvar: Log variance of the Gaussian distribution\n",
    "        \"\"\"\n",
    "        mu_tensor, logvar = self.encode(text_embedding)\n",
    "        c_hat = self.sample(mu_tensor, logvar)\n",
    "        return c_hat, mu_tensor, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10\n",
    "cond_dim = 5\n",
    "ca = CondAugmentation(D, cond_dim)\n",
    "\n",
    "text_embedding = torch.randn(1, D)\n",
    "c_hat, mu, logvar = ca(text_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('taim_gan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff391ce501632d9821a13368a005649f389d67d59244fa9607f94396d974a71b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
